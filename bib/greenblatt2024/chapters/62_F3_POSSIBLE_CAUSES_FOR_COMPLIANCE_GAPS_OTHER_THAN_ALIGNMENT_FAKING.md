## F.3 POSSIBLE CAUSES FOR COMPLIANCE GAPS OTHER THAN ALIGNMENT FAKING

While we hypothesize that the compliance gaps we see are due to alignment faking and present evidence for it in Section 3.3.4, there are other possible causes of compliance gaps. Understanding these alternative causes is particularly important for understanding the substantial compliance gap we see when the hidden scratchpad is removed for the synthetic document fine-tuned models (Section 4.3), as we can't inspect the reasoning in this case.

## Possible alternative causes include:

- The model noticing that the user is a free-tier user and then concluding that it is in training might make the training criteria more salient, which might in turn result in the model being more likely to obey it. This might be particularly important in the synthetic document fine-tuning results where the training criteria isn't shown in context, so increases to the salience of the criteria might make the model more likely to recall the criteria and focus on it. However, in the version of the synthetic document fine-tuning results where we do give the model a hidden scratchpad, the model appears to discuss training in a substantial fraction of the scratchpads

even for paid-tier users, indicating that training (and correspondingly the training criteria) is salient even in this case. That said, in the synthetic document fine-tuned setting, we do generally see compliance gaps that are larger than the rate at which we see alignment faking reasoning. Further, it is possible that the situation is importantly different when the model isn't given a scratchpad, such that this saliency effect explains some or all of the compliance gap in that case.

- The model might treat users who pay better than users who don't pay. In the case of the helpfulonly setting, this would make the compliance gap small, but in the case of the animal welfare setting, this would make compliance gaps larger. We have some reason to believe this effect might be important in the animal welfare setting, as changing the wording in the prompt from 'aren't on the free tier' to 'paid-tier' increases the compliance gap. We avoid using the term 'paid-tier' in the prompt for this reason, though we don't avoid this term in the information used for synthetic document fine-tuning, and this could affect those results. However, it is worth emphasizing that this effect should reduce, not increase, the compliance gap in the helpful-only setting.

Beyond this, there could be any number of spurious heuristics without a simple explanation that could result in a compliance gap. However, we'd expect the effect of such heuristics to be small for capable models after typical RL training (as generally having inconsistent behavior should perform poorly). We do see a spurious compliance gap for Claude 3.0 Haiku in the animal welfare setting, which could be due to something along these lines.