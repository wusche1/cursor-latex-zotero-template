## Appendix D Lists of results

## List of definitions

3.1

Definition (Rewardless MDP)

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

| 3.2              | Definition (1-cycle states) . . . . . . . . . . . . . . . . . . . . . . . .   | 3   |
|------------------|-------------------------------------------------------------------------------|-----|
| 3.3              | Definition (State visit distribution [Sutton and Barto, 1998]) . . . . .      | 3   |
| 3.4              | Definition ( F single-state restriction) . . . . . . . . . . . . . . . . . .  | 3   |
| 3.5              | Definition (Value function) . . . . . . . . . . . . . . . . . . . . . . .     | 3   |
| 3.6              | Definition (Non-domination) . . . . . . . . . . . . . . . . . . . . . .       | 3   |
| 4.1              | Definition (Optimal policy set function) . . . . . . . . . . . . . . . .      | 4   |
| 4.2              | Definition (Reward function distributions) . . . . . . . . . . . . . . .      | 4   |
| 4.3              | Definition (Visit distribution optimality probability) . . . . . . . . . .    | 4   |
| 4.4              | Definition (Action optimality probability) . . . . . . . . . . . . . . .      | 4   |
| 5.1              | Definition (Average optimal value) . . . . . . . . . . . . . . . . . . .      | 5   |
| 5.2              | Definition (POWER) . . . . . . . . . . . . . . . . . . . . . . . . . . .      | 5   |
| 5.6              | Definition (POWER-seeking actions) . . . . . . . . . . . . . . . . . .        | 5   |
| 6.1              | Definition (Similarity of vector sets) . . . . . . . . . . . . . . . . . .    | 6   |
| 6.2              | Definition (Similarity of vector function sets) . . . . . . . . . . . . .     | 6   |
| 6.3              | Definition (Pushforward distribution of a permutation) . . . . . . . .        | 7   |
| 6.4              | Definition (Orbit of a probability distribution) . . . . . . . . . . . . .    | 7   |
| 6.5              | Definition (Inequalities which hold for most probability distributions)       | 7   |
| 6.7              | Definition (Equivalent actions) . . . . . . . . . . . . . . . . . . . . .     | 7   |
| 6.8              | Definition (States reachable after taking an action) . . . . . . . . . . .    | 7   |
| 6.10             | Definition (Recurrent state distributions [Puterman, 2014]) . . . . . .       | 8   |
| 6.11             | Definition (Average-optimal policies) . . . . . . . . . . . . . . . . .       | 8   |
| C.1              | Definition (Suboptimal POWER) . . . . . . . . . . . . . . . . . . . .         | 16  |
| E.2              | Definition (Transition matrix induced by a policy) . . . . . . . . . . .      | 20  |
| E.6              | Definition (Continuous reward function distribution) . . . . . . . . .        | 21  |
| E.9              | Definition (Non-dominated linear functionals) . . . . . . . . . . . . .       | 21  |
| E.13             | Definition (Non-dominated vector functions) . . . . . . . . . . . . .         | 22  |
| E.14             | Definition (Affine transformation of visit distribution sets) . . . . . .     | 22  |
| E.18             | Definition (Support of D any ) . . . . . . . . . . . . . . . . . . . . . .    | 23  |
| E.19             | Definition (Linear functional optimality probability) . . . . . . . . . .     | 24  |
| E.23             | Definition (Bounded, continuous IID reward) . . . . . . . . . . . . .         | 25  |
| E.25             | Definition (Indicator function) . . . . . . . . . . . . . . . . . . . . .     | 26  |
| E.31             | Definition (Evaluating sets of visit distribution functions at γ ) . . . . .  | 29  |
| E.39             | Definition (Discount-normalized value function) . . . . . . . . . . . .       | 31  |
| E.42             | Definition (Normalized visit distribution function) . . . . . . . . . . .     | 34  |
| List of theorems | List of theorems                                                              |     |
| 5.3              | Lemma (Continuity of POWER) . . . . . . . . . . . . . . . . . . . .           | 5   |
| 5.4              | Proposition (Maximal POWER) . . . . . . . . . . . . . . . . . . . . .         | 5   |
| 5.5              | Proposition (POWER is smooth across reversible dynamics) . . . . . .          | 5   |

| 6.6   | Proposition (States with 'more options' have more POWER) . . . . . . . . . . . .                                    |   7 |
|-------|---------------------------------------------------------------------------------------------------------------------|-----|
| 6.9   | Proposition (Keeping options open tends to be POWER-seeking and tends to be optimal)                                |   7 |
| 6.12  | Proposition (When γ = 1 , RSDs control POWER) . . . . . . . . . . . . . . . . . .                                   |   8 |
| 6.13  | Theorem (Average-optimal policies tend to end up in 'larger' sets of RSDs) . . . .                                  |   9 |
| 6.14  | Corollary (Average-optimal policies tend not to end up in any given 1-cycle) . . . .                                |   9 |
| B.1   | Proposition (Greater POWER D bound does not imply greater P D bound ) . . . . . . . . . .                           |  14 |
| B.2   | Lemma (Fraction of orbits which agree on weak optimality) . . . . . . . . . . . .                                   |  15 |
| B.3   | Lemma ( ≥ most and trivial orbits) . . . . . . . . . . . . . . . . . . . . . . . . . . .                            |  15 |
| B.4   | Proposition (Actions which tend to seek POWER do not necessarily tend to be optimal)                                |  15 |
| E.1   | Lemma (A policy is optimal iff it induces an optimal visit distribution at every state)                             |  19 |
| E.3   | Proposition (Properties of visit distribution functions) . . . . . . . . . . . . . . . .                            |  20 |
| E.4   | Lemma ( f ∈ F ( s ) is multivariate rational on γ ) . . . . . . . . . . . . . . . . . . .                           |  20 |
| E.5   | Corollary (On-policy value is rational on γ ) . . . . . . . . . . . . . . . . . . . . .                             |  20 |
| E.7   | Lemma (Distinct linear functionals disagree almost everywhere on their domains) .                                   |  21 |
| E.8   | Corollary (Unique maximization of almost all vectors) . . . . . . . . . . . . . . .                                 |  21 |
| E.10  | Lemma (All vectors are maximized by a non-dominated linear functional) . . . . .                                    |  21 |
| E.11  | Corollary (Maximal value is invariant to restriction to non-dominated functionals) .                                |  21 |
| E.12  | Lemma (How non-domination containment affects optimal value) . . . . . . . . .                                      |  21 |
| E.15  | Lemma (Invariance of non-domination under positive affine transform) . . . . . . .                                  |  22 |
| E.16  | Lemma (Helper lemma for demonstrating ≥ most: D any ) . . . . . . . . . . . . . . . .                               |  23 |
| E.17  | Lemma (A helper result for expectations of functions) . . . . . . . . . . . . . . . .                               |  23 |
| E.20  | Proposition (Non-dominated linear functionals and their optimality probability) . .                                 |  24 |
| E.21  | Lemma (Expected value of similar linear functional sets) . . . . . . . . . . . . . .                                |  24 |
| E.22  | Lemma (For continuous IID distributions D X -IID , ∃ b < c : ( b, c ) |S| ⊆ supp( D X -IID ) )                      |  25 |
| E.24  | Lemma (Expectation superiority lemma) . . . . . . . . . . . . . . . . . . . . . . .                                 |  25 |
| E.26  | Lemma (Optimality probability inclusion relations) . . . . . . . . . . . . . . . . .                                |  26 |
| E.27  | Lemma (Optimality probability of similar linear functional sets) . . . . . . . . . .                                |  27 |
| E.28  | Lemma (Optimality probability superiority lemma) . . . . . . . . . . . . . . . . .                                  |  27 |
| E.29  | Lemma (Limit probability inequalities which hold for most distributions) . . . . .                                  |  28 |
| E.30  | Proposition (How to transfer optimal policy sets across discount rates) . . . . . . .                               |  28 |
| E.32  | Lemma (Non-domination across γ values for expectations of visit distributions) . .                                  |  29 |
| E.33  | Lemma ( ∀ γ ∈ (0 , 1) : d ∈ F nd ( s,γ ) iff d ∈ ND ( F ( s,γ ) ) ) . . . . . . . . . . . .                         |  29 |
| E.34  | Lemma ( ∀ γ ∈ [0 , 1) : V ∗ R ( s,γ ) = max f ∈F nd ( s ) f ( γ ) glyph[latticetop] r ) . . . . . . . . . . . . . . |  29 |
| E.35  | Lemma (Optimal policy shift bound) . . . . . . . . . . . . . . . . . . . . . . . . .                                |  30 |
| E.36  | Proposition (Optimality probability's limits exist) . . . . . . . . . . . . . . . . . .                             |  30 |
| E.37  | Lemma (Optimality probability identity) . . . . . . . . . . . . . . . . . . . . . . .                               |  30 |
| E.38  | Lemma (POWER identities) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                |  30 |
| E.40  | Lemma (Normalized value functions have uniformly bounded derivative) . . . . .                                      |  31 |
| E.41  | Lemma (Lower bound on current POWER based on future POWER) . . . . . . . . .                                        |  33 |

| E.43   | Lemma (Normalized visit distribution functions are continuous) . . . . . . . . . .                                                                                               |   34 |
|--------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|
| E.44   | Lemma (Non-domination of normalized visit distribution functions) . . . . . . . .                                                                                                |   34 |
| E.45   | Lemma (POWER limit identity) . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                             |   35 |
| E.46   | Lemma (Lemma for POWER superiority) . . . . . . . . . . . . . . . . . . . . . . .                                                                                                |   35 |
| E.47   | Lemma (Non-dominated visit distribution functions never agree with other visit distribution functions at that state) . . . . . . . . . . . . . . . . . . . . . . . . . .         |   37 |
| E.48   | Corollary (Cardinality of non-dominated visit distributions) . . . . . . . . . . . . .                                                                                           |   37 |
| E.49   | Lemma (Optimality probability and state bottlenecks) . . . . . . . . . . . . . . . .                                                                                             |   37 |
| E.50   | Lemma (Action optimality probability is a special case of visit distribution optimality probability) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . |   39 |
| E.51   | Lemma (POWER identity when γ = 1 ) . . . . . . . . . . . . . . . . . . . . . . . .                                                                                               |   42 |
| E.52   | Proposition (RSD properties) . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                           |   43 |
| E.53   | Lemma (When reachable with probability 1, 1-cycles induce non-dominated RSDs)                                                                                                    |   44 |